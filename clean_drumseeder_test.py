# -*- coding: utf-8 -*-
"""clean_drumseeder_test

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d5L37GmeycgVZpOfVxrpBYsVWao1mQs-
"""

import requests
import gspread
import json
import pandas as pd
import os
from datetime import datetime
import socket


# Mounting GDrive
from google.colab import drive
drive.mount('/content/drive')

##this is an API call I found on this website https://dharani.telangana.gov.in/gis/

##this request will get the coordinants of a given surveyNumber
cookies = {
    'JSESSIONID': 'XNXlJ9yemFnYL3mCkK4e3MWWlIwwOyy5rw_VuzLg.dharani-app-prod01',
    '_ga': 'GA1.3.991768077.1679558383',
    '_ga_HK5WKYB4EW': 'GS1.3.1689284577.2.1.1689284657.0.0.0',
    '_ga_LZ69DSV6N1': 'GS1.3.1692168204.1.1.1692168657.0.0.0',
    '_ga_31KEQNSXCP': 'GS1.3.1695731677.1.0.1695731677.0.0.0',
}

headers = {
    'authority': 'dharani.telangana.gov.in',
    'accept': 'application/json, text/javascript, */*; q=0.01',
    'accept-language': 'en-US,en;q=0.9',
    'content-type': 'application/json',
    # 'cookie': 'JSESSIONID=XNXlJ9yemFnYL3mCkK4e3MWWlIwwOyy5rw_VuzLg.dharani-app-prod01; _ga=GA1.3.991768077.1679558383; _ga_HK5WKYB4EW=GS1.3.1689284577.2.1.1689284657.0.0.0; _ga_LZ69DSV6N1=GS1.3.1692168204.1.1.1692168657.0.0.0; _ga_31KEQNSXCP=GS1.3.1695731677.1.0.1695731677.0.0.0',
    'origin': 'https://dharani.telangana.gov.in',
    'referer': 'https://dharani.telangana.gov.in/gis/',
    'sec-ch-ua': '"Chromium";v="118", "Google Chrome";v="118", "Not=A?Brand";v="99"',
    'sec-ch-ua-mobile': '?0',
    'sec-ch-ua-platform': '"Windows"',
    'sec-fetch-dest': 'empty',
    'sec-fetch-mode': 'cors',
    'sec-fetch-site': 'same-origin',
    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36',
    'x-requested-with': 'XMLHttpRequest',
}

#Making a new directory
!mkdir -p '/content/drive/MyDrive/Colab Notebook/output/'

# Master Excel file path
master_file_path = '/content/drive/MyDrive/Colab Notebook/output/master_output_10.xlsx'

# Check if the master file already exists
if os.path.exists(master_file_path):
    # Read the existing master file
    master_df = pd.read_excel(master_file_path)
else:
    # If the master file doesn't exist, create an empty DataFrame
    master_df = pd.DataFrame()

#Input file
excel_file_path = '/content/drive/MyDrive/Colab Notebook/input for scraping_2.xlsx'
# Read the Excel file into a DataFrame
input_data_df = pd.read_excel(excel_file_path)

# Iterate over rows in the DataFrame
for index, row in input_data_df.iterrows():
    # Extract village code and survey number from each row
    village_code = int(row['village_code'])  # Adjust column name based on your Excel file
    survey_number = int(row['survey_code'])  # Adjust column name based on your Excel file

    '''
    if village_code==nan:
      village_code = str((row['village_code']))
      survey_number = str((row['survey_code']))
    else:
      village_code = str(int(row['village_code']))
      survey_number = str(int (row['survey_code']))
    '''
    print(survey_number)
    print(village_code)

    # Create json_data using the extracted values
    json_data = {
      'villageCode': village_code,
      'surveyNumber': survey_number,
      }

    # The next few lines (date, time, hostname, ip address) are for monitoring purpose
    #get current date and time
    current_datetime = datetime.now()

    # Get the hostname of the local machine
    hostname = socket.gethostname()

    # Get the IP address of the local machine
    ip_address = socket.gethostbyname(hostname)

    print(f"Hostname: {hostname}")
    print(f"IP Address: {ip_address}")

    try:
      response = requests.post(
        'https://dharani.telangana.gov.in/gis/api/gis/getsurveyidfeature',
        cookies=cookies,
        headers=headers,
        json=json_data,
        timeout=120  # Adjust the timeout value as needed (in seconds)
        )


      # Parse the JSON response
      response_json = json.loads(response.content)


      # Extract information from the JSON
      process= response_json[0]['feat_json']['value']
      geojson= json.loads(process)

      if geojson['features'] is not None:

        print(f"data getting scraped, village code:{village_code},survey_number:{survey_number}")

        feature= geojson['features'][0]
        geometry = feature['geometry']['coordinates']
        feature_id = feature['properties']['feature_id']
        village_id = feature['properties']['village_id']
        survey_number = feature['properties']['survey_number']

        # Create a DataFrame
        coord = pd.DataFrame({
          'Feature_ID': [feature_id],
          'Village_ID': [village_id], #should be village_code
          'Survey_Number': [survey_number],
          'Coordinates': [geometry],
          'dateandtime': [current_datetime]

          })

        # Append the new data to the master DataFrame
        master_df = pd.concat([master_df, coord], ignore_index=True)


      else:
        # Create a DataFrame
        print(geojson.keys())
        print(response.content)
        print(f"NOT getting scraped, village code:{village_code},survey_number:{survey_number}")
        coord = pd.DataFrame({
          'Feature_ID': "Data not scraped",
          'Village_ID': [village_code],
          'Survey_Number': [survey_number],
          'Coordinates': "Data not scraped",
          'dateandtime': [current_datetime]
          })

        # Append the new data to the master DataFrame
        master_df = pd.concat([master_df, coord], ignore_index=True)

    except requests.exceptions.Timeout:
        print(f"Timeout error for survey_number: {survey_number}, village_code: {village_code}")

# Write the updated master DataFrame to the master file
master_df.to_excel(master_file_path, index=False)

#pip install geojson

import json
import requests
import gspread
import json
import pandas as pd
import os
import geojson
import ast


# Mounting GDrive
from google.colab import drive
drive.mount('/content/drive')


#Input file
excel_file_path = '/content/drive/MyDrive/Colab Notebook/output/master_output_9_clean.xlsx'
# Read the Excel file into a DataFrame
master_df = pd.read_excel(excel_file_path)
# Convert the master DataFrame to GeoJSON format
features = []
print("Starting loop")

for index, row in master_df.iterrows():
    try:
        # Assuming 'Coordinates' column contains valid GeoJSON strings
        coordinates = ast.literal_eval(row['Coordinates'])
        geometry = geojson.Polygon([coordinates])  # Create a GeoJSON Polygon


        feature = geojson.Feature(

          geometry=geometry,
          properties={
            #'geometry': row['Coordinates']
            'Feature_ID': row['Feature_ID'],
            'Village_ID': row['Village_ID'],
            'Survey_Number': row['Survey_Number']

            }
          )
        features.append(feature)

    except (ValueError, TypeError) as e:
        print(f"Skipping row  due to invalid 'Coordinates': {e}")

    '''
    coordinates = row['Coordinates']
    #print(coordinates)
    # Create a GeoJSON LineString or MultiPoint object, depending on your data
    # Adjust this part based on the structure of your 'Coordinates' data
    geometry_1 =str(coordinates)
    #print(geometry_1)
    '''


feature_collection = geojson.FeatureCollection(features)

for feature in features[:5]:
    print(feature['properties'])

# Save the GeoJSON data to a file
output_geojson_path = '/content/drive/MyDrive/Colab Notebook/output/master_output_clean.geojson'
with open(output_geojson_path, 'w') as f:
    geojson.dump(feature_collection, f)

# Write the updated master DataFrame to the master file
master_df.to_excel(excel_file_path, index=False)

pip install geojson